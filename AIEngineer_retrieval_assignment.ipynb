{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "oSPcZYxSdhiP",
   "metadata": {
    "id": "oSPcZYxSdhiP"
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0a0376a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/selen/OneDrive/Proyectos/Waywand_search/env/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b781e47-2986-4c1d-b1f6-28361312aa93",
   "metadata": {
    "id": "8b781e47-2986-4c1d-b1f6-28361312aa93",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from libs.auxiliar_func import *\n",
    "from libs.visualization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2384d13-941a-4c49-b903-68c5cf55ac15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f2384d13-941a-4c49-b903-68c5cf55ac15",
    "outputId": "901b9c77-6583-4d9d-e247-c066665a0b58",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'WANDS' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "#clone the git repo that contains the data and additional information about the dataset\n",
    "!git clone https://github.com/wayfair/WANDS.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad91af1d-d710-44be-9991-c5fd1ba7e7ff",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "NojWJKesLan1",
   "metadata": {
    "id": "NojWJKesLan1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mReading WAYFAIR data with pandas \u001b[0m\n",
      "\u001b[1;34m Load bert model \u001b[0m\n",
      "\u001b[1;32m Creating embeddings ...... \u001b[0m\n",
      "\u001b[1;32m Done ! \u001b[0m\n",
      "\u001b[1;34m Getting IDS and top products \u001b[0m\n",
      "\u001b[1;32m Creating top 10 product ids ...... \u001b[0m\n",
      "\u001b[1;32m Creating exact match product IDs...... \u001b[0m\n",
      "\u001b[1;32m Creating map@k score...... \u001b[0m\n",
      "\u001b[1;32m Done...... \u001b[0m\n",
      "\u001b[1;35m Score of the model: 0.3776823743386243 \u001b[0m\n",
      "\u001b[1;34m Saving embeddings into Pinecone ... \u001b[0m\n",
      "\u001b[1;34m Uploaded 42994 embeddings to Pinecone \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "print(f'{bcolors.BOLD_BLUE}Reading WAYFAIR data with pandas {bcolors.ENDC}')\n",
    "product_df = pd.read_csv(\"WANDS/dataset/product.csv\", sep='\\t')\n",
    "query_df = pd.read_csv(\"WANDS/dataset/query.csv\", sep='\\t')\n",
    "label_df = pd.read_csv(\"WANDS/dataset/label.csv\", sep='\\t')\n",
    "\n",
    "#group the labels for each query to use when identifying exact matches\n",
    "grouped_label_df = label_df.groupby('query_id')\n",
    "\n",
    "# Load BERT model\n",
    "print(f'{bcolors.BOLD_BLUE} Load bert model {bcolors.ENDC}')\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "# Compute BERT embeddings \n",
    "print(f'{bcolors.BOLD_GREEN} Creating embeddings ...... {bcolors.ENDC}')\n",
    "#product_embeddings = create_product_embeddings(product_df,model)\n",
    "print(f'{bcolors.BOLD_GREEN} Done ! {bcolors.ENDC}')\n",
    "\n",
    "product_df['embeddings']=product_embeddings.tolist()\n",
    "\n",
    "#applying the function to obtain top product IDs and adding top K product IDs to the dataframe\n",
    "print(f'{bcolors.BOLD_BLUE} Getting IDS and top products {bcolors.ENDC}')\n",
    "\n",
    "# Create a top 10 products based on cosine similarities (the function is store in auxiliar_func.py)\n",
    "print(f'{bcolors.BOLD_GREEN} Creating top 10 product ids ...... {bcolors.ENDC}')\n",
    "query_df['top_product_ids'] = query_df['query'].apply(lambda q: get_top_10(q, model, product_df))\n",
    "\n",
    "\n",
    "#adding the list of exact match product_IDs from labels_df\n",
    "print(f'{bcolors.BOLD_GREEN} Creating exact match product IDs...... {bcolors.ENDC}')\n",
    "query_df['relevant_ids'] = query_df['query_id'].apply(lambda q: get_exact_matches_for_query(q, grouped_label_df))\n",
    "\n",
    "#now assign the map@k score\n",
    "print(f'{bcolors.BOLD_GREEN} Creating map@k score...... {bcolors.ENDC}')\n",
    "query_df['map@k'] = query_df.apply(lambda x: map_at_k(x['relevant_ids'], x['top_product_ids'], k=10), axis=1)\n",
    "\n",
    "print(f'{bcolors.BOLD_GREEN} Done...... {bcolors.ENDC}')\n",
    "# calculate the MAP across the entire query set\n",
    "score = query_df.loc[:, 'map@k'].mean()\n",
    "print(f'{bcolors.BOLD_MAGENTA} Score of the model: {score} {bcolors.ENDC}')\n",
    "\n",
    "\n",
    "print(f'{bcolors.BOLD_BLUE} Saving embeddings into Pinecone ... {bcolors.ENDC}')\n",
    "\n",
    "#API key\n",
    "load_dotenv()\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_ENV = os.getenv(\"PINECONE_ENV\")\n",
    "\n",
    "# Pinecone\n",
    "pc = Pinecone(api_key= PINECONE_API_KEY)\n",
    "\n",
    "# index name\n",
    "INDEX_NAME = \"product-search-2\"\n",
    "\n",
    "# index \n",
    "if INDEX_NAME not in pc.list_indexes():\n",
    "    pc.create_index(\n",
    "        INDEX_NAME,\n",
    "        dimension=len(product_df[\"embeddings\"].iloc[0]),\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\"))\n",
    "\n",
    "# Connect to the index\n",
    "index = pc.Index(INDEX_NAME)\n",
    "\n",
    "# Converting embeddings into Pinecone format\n",
    "vectors = [\n",
    "    (str(i), np.array(embedding).tolist(), {\"product_name\": product_name})\n",
    "    for i, (product_name, embedding) in enumerate(zip(product_df[\"product_name\"], product_df[\"embeddings\"]))\n",
    "]\n",
    "\n",
    "# Uploading in batches\n",
    "batch_size = 100\n",
    "for i in range(0, len(vectors), batch_size):\n",
    "    index.upsert(vectors[i:i + batch_size])\n",
    "\n",
    "print(f'{bcolors.BOLD_BLUE} Uploaded {len(vectors)} embeddings to Pinecone {bcolors.ENDC}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
